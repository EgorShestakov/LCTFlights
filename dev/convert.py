import json
import os
from typing import Dict, List, Any
import geopandas as gpd
from sqlalchemy import create_engine


def json_to_postgis_regions(json_file_path: str, output_file_path: str = None) -> Dict[str, Any]:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç JSON —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ PostGIS —Ñ–æ—Ä–º–∞—Ç.

    Args:
        json_file_path (str): –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É JSON —Ñ–∞–π–ª—É
        output_file_path (str, optional): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.

    Returns:
        Dict[str, Any]: –°–ª–æ–≤–∞—Ä—å –≤ PostGIS —Ñ–æ—Ä–º–∞—Ç–µ
    """

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    if not os.path.exists(json_file_path):
        raise FileNotFoundError(f"–§–∞–π–ª {json_file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    file_size = os.path.getsize(json_file_path)
    if file_size == 0:
        raise ValueError(f"–§–∞–π–ª {json_file_path} –ø—É—Å—Ç–æ–π")

    print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")

    try:
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
        encodings = ['utf-8', 'utf-8-sig', 'cp1251', 'iso-8859-1']

        for encoding in encodings:
            try:
                with open(json_file_path, 'r', encoding=encoding) as f:
                    content = f.read().strip()
                    print(f"–ü–æ–ø—ã—Ç–∫–∞ —á—Ç–µ–Ω–∏—è —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {encoding}")
                    print(f"–ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤: {content[:500]}")

                    if not content:
                        raise ValueError("–§–∞–π–ª –ø—É—Å—Ç–æ–π –ø–æ—Å–ª–µ —á—Ç–µ–Ω–∏—è")

                    regions_data = json.loads(content)
                    print(f"–£—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω–æ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {encoding}")
                    break

            except UnicodeDecodeError:
                print(f"–û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ {encoding}, –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é...")
                continue
            except json.JSONDecodeError as e:
                print(f"–û—à–∏–±–∫–∞ JSON —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π {encoding}: {e}")
                # –ï—Å–ª–∏ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞, –≤—ã–±—Ä–æ—Å–∏–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ
                if encoding == encodings[-1]:
                    raise e
                continue
        else:
            raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –Ω–∏ —Å –æ–¥–Ω–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π")

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
        with open(json_file_path, 'rb') as f:
            raw_content = f.read()
            print(f"–°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ (–ø–µ—Ä–≤—ã–µ 200 –±–∞–π—Ç): {raw_content[:200]}")
        raise

    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è PostGIS
    postgis_data = {
        "type": "FeatureCollection",
        "features": []
    }

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
    if not isinstance(regions_data, dict):
        raise ValueError(f"–û–∂–∏–¥–∞–ª—Å—è —Å–ª–æ–≤–∞—Ä—å, –ø–æ–ª—É—á–µ–Ω {type(regions_data)}")

    print(f"–ù–∞–π–¥–µ–Ω–æ —Ä–µ–≥–∏–æ–Ω–æ–≤: {len(regions_data)}")

    for region_name, region_data in regions_data.items():
        print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–≥–∏–æ–Ω: {region_name}")

        # –°–æ–∑–¥–∞–µ–º feature –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞
        feature = {
            "type": "Feature",
            "properties": {
                "name": region_name
            },
            "geometry": {
                "type": "MultiPolygon",
                "coordinates": []
            }
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö —Ä–µ–≥–∏–æ–Ω–∞
        if not isinstance(region_data, dict):
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –¥–∞–Ω–Ω—ã–µ —Ä–µ–≥–∏–æ–Ω–∞ {region_name} –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            continue

        polygons = []
        valid_polygons_count = 0

        for polygon_key, polygon_coords in region_data.items():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            if not polygon_coords or not isinstance(polygon_coords, list):
                continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–∞–ª–∏–¥–Ω—ã
            valid_coords = []
            for coord in polygon_coords:
                if (isinstance(coord, list) and len(coord) == 2 and
                        all(isinstance(x, (int, float)) for x in coord)):
                    valid_coords.append(coord)

            if len(valid_coords) >= 3:  # –ü–æ–ª–∏–≥–æ–Ω –¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å –º–∏–Ω–∏–º—É–º 3 —Ç–æ—á–∫–∏
                # –ó–∞–º—ã–∫–∞–µ–º –ø–æ–ª–∏–≥–æ–Ω
                if valid_coords[0] != valid_coords[-1]:
                    valid_coords.append(valid_coords[0])

                polygons.append([valid_coords])  # MultiPolygon —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è
                valid_polygons_count += 1

        print(f"–†–µ–≥–∏–æ–Ω {region_name}: –Ω–∞–π–¥–µ–Ω–æ {valid_polygons_count} –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ–ª–∏–≥–æ–Ω–æ–≤")

        if polygons:
            feature["geometry"]["coordinates"] = polygons
            postgis_data["features"].append(feature)
        else:
            print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ {region_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ–ª–∏–≥–æ–Ω–æ–≤")

    print(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–µ–≥–∏–æ–Ω–æ–≤: {len(postgis_data['features'])}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    if output_file_path:
        try:
            with open(output_file_path, 'w', encoding='utf-8') as f:
                json.dump(postgis_data, f, ensure_ascii=False, indent=2)
            print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {output_file_path}")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}")

    return postgis_data


# –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
def diagnose_json_file(file_path: str):
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º —Å JSON —Ñ–∞–π–ª–æ–º"""
    print(f"=== –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–∞ {file_path} ===")

    if not os.path.exists(file_path):
        print("–§–∞–π–ª –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return

    file_size = os.path.getsize(file_path)
    print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç")

    if file_size == 0:
        print("–§–∞–π–ª –ø—É—Å—Ç–æ–π")
        return

    # –ß–∏—Ç–∞–µ–º —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ
    with open(file_path, 'rb') as f:
        raw_data = f.read()
        print(f"–ü–µ—Ä–≤—ã–µ 200 –±–∞–π—Ç: {raw_data[:200]}")
        print(f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ 200 –±–∞–π—Ç: {raw_data[-200:]}")

    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
    encodings = ['utf-8', 'utf-8-sig', 'cp1251', 'iso-8859-1']

    for encoding in encodings:
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                content = f.read()
                print(f"\n=== –ö–æ–¥–∏—Ä–æ–≤–∫–∞ {encoding} ===")
                print(f"–î–ª–∏–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
                print(f"–ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤: {repr(content[:500])}")

                # –ü—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
                data = json.loads(content)
                print("‚úì JSON –≤–∞–ª–∏–¥–µ–Ω!")
                print(f"–¢–∏–ø –∫–æ—Ä–Ω–µ–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞: {type(data)}")
                if isinstance(data, dict):
                    print(f"–ö–ª—é—á–∏: {list(data.keys())[:5]}...")  # –ü–µ—Ä–≤—ã–µ 5 –∫–ª—é—á–µ–π
                return data

        except UnicodeDecodeError as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏: {e}")
        except json.JSONDecodeError as e:
            print(f"‚úó –û—à–∏–±–∫–∞ JSON: {e}")
        except Exception as e:
            print(f"‚úó –î—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞: {e}")

    return None


def load_with_geopandas(geojson_file, db_connection_string):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç GeoJSON –∏—Å–ø–æ–ª—å–∑—É—è GeoPandas
    """
    # –ß–∏—Ç–∞–µ–º GeoJSON
    gdf = gpd.read_file(geojson_file)

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∏—Å—Ç–µ–º—É –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (WGS84)
    gdf = gdf.set_crs('EPSG:4326')

    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –±–∞–∑–µ
    engine = create_engine(db_connection_string)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –±–∞–∑—É
    gdf.to_postgis(
        name='regions',
        con=engine,
        if_exists='replace',  # –∏–ª–∏ 'append' –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        index=True
    )

    print("–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —á–µ—Ä–µ–∑ GeoPandas!")


import geopandas as gpd
from sqlalchemy import create_engine
import json


def simple_geojson_to_postgis(geojson_file):
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ GeoJSON –≤ PostGIS
    """
    try:
        # 1. –ß–∏—Ç–∞–µ–º GeoJSON —Ñ–∞–π–ª
        print("–ß–∏—Ç–∞–µ–º GeoJSON —Ñ–∞–π–ª...")
        gdf = gpd.read_file(geojson_file)
        print(f"–ü—Ä–æ—á–∏—Ç–∞–Ω–æ {len(gdf)} —Ä–µ–≥–∏–æ–Ω–æ–≤")

        # 2. –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–∏—Å—Ç–µ–º—É –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (WGS84)
        gdf = gdf.set_crs('EPSG:4326')

        # 3. –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç—Ä–æ–∫—É –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        # –ó–ê–ú–ï–ù–ò–¢–ï –ø–∞—Ä–æ–ª—å –Ω–∞ —Ç–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π —É–∫–∞–∑–∞–ª–∏ –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ PostgreSQL!
        connection_string = 'postgresql://postgres:–≤–∞—à_–ø–∞—Ä–æ–ª—å@localhost:5432/postgres'

        # 4. –°–æ–∑–¥–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ
        engine = create_engine(connection_string)

        # 5. –°–æ–∑–¥–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        with engine.connect() as conn:
            conn.execute("COMMIT")  # –ó–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â—É—é —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é
            conn.execute("CREATE DATABASE IF NOT EXISTS russia_regions")

        # 6. –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –Ω–æ–≤–æ–π –±–∞–∑–µ
        connection_string_db = 'postgresql://postgres:–≤–∞—à_–ø–∞—Ä–æ–ª—å@localhost:5432/russia_regions'
        engine_db = create_engine(connection_string_db)

        # 7. –í–∫–ª—é—á–∞–µ–º PostGIS —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        with engine_db.connect() as conn:
            conn.execute("CREATE EXTENSION IF NOT EXISTS postgis")

        # 8. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É
        print("–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É...")
        gdf.to_postgis(
            name='regions',
            con=engine_db,
            if_exists='replace',  # –ó–∞–º–µ–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            index=True
        )

        print("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –±–∞–∑—É!")
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(gdf)} —Ä–µ–≥–∏–æ–Ω–æ–≤")

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ Shapefile (–ø—Ä–æ—â–µ!)
def geojson_to_shapefile(geojson_file, output_shapefile):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º GeoJSON –≤ Shapefile - –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö!
    """
    try:
        gdf = gpd.read_file(geojson_file)
        gdf = gdf.set_crs('EPSG:4326')
        gdf.to_file(output_shapefile, driver='ESRI Shapefile')
        print(f"‚úÖ Shapefile —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫: {output_shapefile}")
        return True
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


if __name__ == "__main__":
    # –°–ø–æ—Å–æ–± 1: –ó–∞–≥—Ä—É–∑–∫–∞ –≤ PostGIS (—Ç—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π PostgreSQL)
    # simple_geojson_to_postgis('Regions_postgis.json')

    # –°–ø–æ—Å–æ–± 2: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ Shapefile (–Ω–µ —Ç—Ä–µ–±—É–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö!)
    geojson_to_shapefile('Regions_postgis.json', 'regions_shapefile')


# # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
# if __name__ == "__main__":
#     # input_file = "../Regions.json"
#     # output_file = "Regions_postgis.json"
#     #
#     # # –°–Ω–∞—á–∞–ª–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª
#     # print("–ó–∞–ø—É—Å–∫–∞–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É...")
#     # data = diagnose_json_file(input_file)
#     #
#     # if data is not None:
#     #     print("\n–§–∞–π–ª –≤–∞–ª–∏–¥–µ–Ω, –∑–∞–ø—É—Å–∫–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é...")
#     #     result = json_to_postgis_regions(input_file, output_file)
#     #     print("–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
#     # else:
#     #     print("\n–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –ø–µ—Ä–µ–¥ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π")
#     connection_string = 'postgresql://postgres:postgres@localhost:5432/LCTFlights'
#
#     load_with_geopandas('Regions_postgis.json', connection_string)
